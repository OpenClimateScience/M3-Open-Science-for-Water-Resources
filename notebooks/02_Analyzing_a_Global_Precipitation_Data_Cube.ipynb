{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72887a5-e703-4b09-aebd-80e1af46fe41",
   "metadata": {},
   "source": [
    "# M3.2 - Analyzing a Global Precipitation Data Cube\n",
    "\n",
    "*Part of:* [**Open Science for Water Resources**](https://github.com/OpenClimateScience/M3-Open-Science-for-Water-Resources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd1732-3f0f-4a7d-96bd-c72c248ceacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import earthaccess\n",
    "import numpy as np\n",
    "import h5py\n",
    "import xarray as xr\n",
    "from matplotlib import pyplot\n",
    "\n",
    "auth = earthaccess.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c021e2-a875-4c9d-92ca-c818b04d95f0",
   "metadata": {},
   "source": [
    "The terrestrial water cycle consists of **stocks** and **flows** of water. Stocks include any long-term storage of water: lakes, reservoirs, groundwater, and atmospheric water vapor. Flows include any movement of water from one stock to another.\n",
    "\n",
    "Just like with bank accounts, we can study flows to get a good idea of the overall picture. If we see a lot of money leaving one account, we can infer that the account balance, and the available money, may be low. We might create a budget to quantify money flowing into the account and money flowing out, in order to calculate whether the balance is growing or shrinking.\n",
    "\n",
    "**To study water availability in a basin or watershed, we can look at the water budget:**\n",
    "$$\n",
    "P = E + R + \\Delta S\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $P$ is the precipitation, assumed to be the only way that water enters a basin.\n",
    "- $E$ is the **evapotranspiration,** or the sum of water that is evaporated or that is drawn up from the soil by plants (transpired).\n",
    "- $R$ is the runoff, or water that leaves the basin through overland flow, usually a central river.\n",
    "- $\\Delta S$ is the change in storage; this generally means the change in available water, mostly groundwater.\n",
    "\n",
    "The idea behind the water budget is that after accounting for water inputs ($P$) and outputs ($E$ and $R$), we should be able to quantify how much the basin's available water storage is growing or shrinking ($\\Delta S$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae08b036-a6a1-44f6-9c41-99f3be730ad3",
   "metadata": {},
   "source": [
    "**Here's an illustration of these water flows within a watershed:**\n",
    "\n",
    "![](./assets/water_budget.png)\n",
    "\n",
    "[*Image courtesy of the USGS*](https://www.usgs.gov/media/images/components-a-simple-water-budget-part-a-watershed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797d5410-8243-4817-88c7-a9a52cedea75",
   "metadata": {},
   "source": [
    "So, to compute a water balance, we need at least three things: precipitation, runoff, and evapotranspiration data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30a1e97-25a0-4324-a2df-4e0210d15b28",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Calculating basin-scale precipitation\n",
    "\n",
    "The basin we'll consider for this study is the Yellowstone River basin. The runoff of this basin is gauged in the Yellowstone River near Sidney, Montana (U.S.A.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcef2ad1-93e4-4a74-a6fd-0f69ca677932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas\n",
    "\n",
    "basin = geopandas.read_file('/home/arthur.endsley/Workspace/NTSG/projects/Y2024_TOPS_Training/data/YellowstoneRiver_drainage_WSG84.shp')\n",
    "river = geopandas.read_file('/home/arthur.endsley/Workspace/NTSG/projects/Y2024_TOPS_Training/data/YellowstoneRiver_course_WSG84.shp')\n",
    "states = geopandas.read_file('/home/arthur.endsley/Workspace/NTSG/projects/Y2024_TOPS_Training/data/YellowstoneRiver_states_WGS84.shp')\n",
    "basin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac42ad-b6ae-45f3-8eac-f16b4e2bff76",
   "metadata": {},
   "source": [
    "Below is a plot of our study area, showing the drainage area (basin) of the Yellowstone River. Where the River exits the basin is our gauging station, in eastern Montana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a881ccb7-dbd2-45d4-817c-df9371d715a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = states.plot(edgecolor = 'black', color = 'lightgray')\n",
    "basin.plot(ax = ax, edgecolor = 'darkblue', color = 'none')\n",
    "river.plot(ax = ax, edgecolor = 'green', label = 'Yellowstone River')\n",
    "pyplot.legend(loc = 'lower left')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ebaa7-2965-455c-a350-d486016ba5ae",
   "metadata": {},
   "source": [
    "### Downloading IMERG-Final precipitation data\n",
    "\n",
    "To calculate the amount of precipitation entering the basin, we'll use [NASA's IMERG-Final dataset, which was described in detail in a previous lesson.](https://github.com/OpenClimateScience/M1-Open-Climate-Data/blob/main/notebooks/05_Earth_Observation_Data.ipynb) Specifically, we'll use a monthly version of IMERG-Final that estimates the precipitation rate on a global grid.\n",
    "\n",
    "&#x1F449; [Read the documentation for IMERG-Final monthly data](https://dx.doi.org/10.5067/GPM/IMERG/3B-MONTH/07)\n",
    "\n",
    "Let's download 10 years of monthly precipitation data, from 2014 through 2023.\n",
    "\n",
    "&#x1F449; **Note that you must create the directory you want to put the data in, first. Here, we assume you want to put it in a directory called `data/IMERG-Final_monthly`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48a826b-ede4-4165-b32d-a9db68e52dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = earthaccess.search_data(\n",
    "    short_name = 'GPM_3IMERGM',\n",
    "    temporal = ('2014-01-01', '2023-12-31'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f1f43c-9273-495e-a97b-be7071bf713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthaccess.download(results, 'data/IMERG-Final_monthly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709b273f-b2c4-4d01-b80e-3d294965686f",
   "metadata": {},
   "source": [
    "### Working with multiple HDF5 files\n",
    "\n",
    "The IMERG-Final data are in HDF5 format, which can be difficult to work with when we are interested in the spatial coordinates. Our preferred library, `xarray`, doesn't know how to interpret the coordinate systems of HDF5 files, so let's confirm some basic details ourselves after opening one of the data granules with the `h5py` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ac121-2181-4755-8791-6365c95cea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('data/IMERG-Final_monthly/3B-MO.MS.MRG.3IMERG.20180701-S000000-E235959.07.V07B.HDF5', 'r') as hdf:\n",
    "    longitude = hdf['Grid/lon'][:]\n",
    "    latitude = hdf['Grid/lat'][:]\n",
    "    print(longitude.shape)\n",
    "    print(latitude.shape)\n",
    "    print(hdf['Grid/precipitation'].shape)\n",
    "    print(hdf['Grid/precipitation'].attrs['units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d36e0b-4155-4de0-a0b4-d627c8d532e5",
   "metadata": {},
   "source": [
    "It seems our data are on a longitude-latitude grid, with 3600 columns and 1800 rows. This corresponds to a spatial resolution of 0.1 degrees. The units of precipitation are millimeters per hour (mm/hr).\n",
    "\n",
    "We have 10 years of monthly data, so we should have 120 files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8d254-1ef1-413a-ad48-c93f77bc55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob('data/IMERG-Final_monthly/*.HDF5')\n",
    "file_list.sort()\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4baa738-4e34-46cb-8340-d578ba8c1cd4",
   "metadata": {},
   "source": [
    "The date information for each file can be extracted from the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb27c952-5a18-42ff-ae3d-a3d6afc9237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list[0].split('.')[4][0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a2212f-619b-476a-b36c-ff8ee5f7d118",
   "metadata": {},
   "source": [
    "Now let's see how we would open these data using `xarray`. \n",
    "\n",
    "#### &#x1F6A9; <span style=\"color:red\">Reading HDF5 Files with `xarray`</red>\n",
    "\n",
    "Again, because it's an HDF5 file, it is difficult for `xarray` to interpret the coordinate systems and structure of the file. So, when using `xr.open_dataset()`, we need to:\n",
    "\n",
    "- Indicate that the `group` in which our datasets are stored is called `'Grid'`\n",
    "- Tell `xarray` not to try and interpret any date or time information: `decode_times = False`\n",
    "\n",
    "We're only interested in the `'precipitation'` dataset, so we use the `get()` method to subset our `xarray` Dataset to just this variable.\n",
    "\n",
    "Furthermore, because `xarray` doesn't know much about HDF5 files, we need to use `assign_coords()` to define the coordinates of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967718e-0d0b-45a1-ba84-d7b3290bf1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = file_list[0]\n",
    "\n",
    "# We only care about the \"precipitation\" variable, but we want an xarray.Dataset,\n",
    "#    so we include the name of the variable(s) we want as a list in get()\n",
    "ds = xr.open_dataset(filename, group = 'Grid', decode_times = False).get(['precipitation'])\n",
    "\n",
    "# Define the missing coordinates\n",
    "date = datetime.datetime.strptime(filename.split('.')[4][0:8], '%Y%m%d') # e.g., \"20180101\"\n",
    "ds = ds.assign_coords({\n",
    "    'time': [date], 'x': longitude, 'y': latitude\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb04c18-4613-4802-b18e-9d46c2d6e841",
   "metadata": {},
   "source": [
    "Finally, we're ready to visualize our data. To enhance some of the patterns in the data, let's set `vmax = 1`, so that our colorbar stretches only to 1 mm/hr at the high end.\n",
    "\n",
    "The plot may look strange because the IMERG-Final product quantifies precipitation over both land and the oceans. However, you should be able to identify western Europe and Iceland in the top-center of the image. Also note that the tropics, as expected, receive a lot of precipitation relative to the rest of the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e5437-c603-4590-910e-6c4cbe449229",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.precipitation.plot(x = 'lon', vmax = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ed8b48-87b7-4e59-b278-c64013af0ec4",
   "metadata": {},
   "source": [
    "### Spatial coordinate reference systems\n",
    "\n",
    "Spatial datasets are special. In addition to the data values they contain (e.g., precipitation), each value is associated with *spatial coordinates* that describe a point on the earth.\n",
    "\n",
    "Because our datasets are often 2-dimensional, flat representations (like the precipitation data above), we need a way of locating each pixel in our flat dataset on the round earth. A **coordinate reference system (CRS)** describes how the flat representation relates to the earth.\n",
    "\n",
    "**A CRS is often described using a unique identifier known as an EPSG code,** where EPSG stands for the European Petroleum Survey Group.\n",
    "\n",
    "&#x1F449; You can learn more about EPSG codes, and look up the code for a specific CRS, at [the epsg.io website.](https://epsg.io/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877375e0-be33-4099-8dc3-e0761a4350d2",
   "metadata": {},
   "source": [
    "### Spatial subsetting of an `xarray` Dataset\n",
    "\n",
    "This is a global dataset, but we're only interested in precipitation in the Yellowstone River basin. We've previously seen how to subset an `xarray` dataset to a specific point or within a rectangular bounding box. But how can we subset the data to an irregular shape, like a drainage basin?\n",
    "\n",
    "&#x1F449; **First, we need to define the spatial coordinate system of our data. We can do this by accessing the `rio` property of a Dataset.**\n",
    "\n",
    "#### &#x1F6A9; <span style=\"color:red\">Pay Attention</red>\n",
    "\n",
    "**In order for the following example to work, we must have the module `rioxarray` installed.** (It doesn't need to be imported, but it does need to be installed.)\n",
    "\n",
    "The `rio` property of a Dataset is accessed as `ds.rio`, if the Dataset is named `ds`. `ds.rio` gives us access to all sorts of tools for manipulating the spatial coordinates and attributes of a spatial dataset. It's name comes from the `rasterio` library, which is often abbreviated as `rio`.\n",
    "\n",
    "**Let's define the coordinate reference system (CRS) of our data using it's EPSG code. For longitude-latitude data, we can usually assume it is best described by the WGS84 Geographic Coordinate System, which has the EPSG code 4326.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e26ebbd-68b0-4318-84c5-2fca9b000f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import CRS\n",
    "\n",
    "# NOTE: We must have rioxarray installed to be able to access the \n",
    "#  \"rio\" property of xarray Datasets; here, we define the CRS of this\n",
    "#  dataset, which was previously undefined\n",
    "\n",
    "# Tell xarray that this dataset's CRS is the WGS84 Geographic Coordinate System\n",
    "ds = ds.rio.write_crs(CRS.from_epsg(4326))\n",
    "\n",
    "# Also, we need to indicate which of the coordinates correspond to X and Y dimensions\n",
    "ds = ds.rio.set_spatial_dims(x_dim = 'lon', y_dim = 'lat')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dee81f4-4e6e-4b37-baa8-ee278fd96072",
   "metadata": {},
   "source": [
    "**With the CRS and spatial coordinates defined, it's very easy to clip our precipitation grid to the bounds of our basin.**\n",
    "\n",
    "#### &#x1F6A9; <span style=\"color:red\">Pay Attention</red>\n",
    "\n",
    "For this to work, the CRS of our gridded data, `ds`, must be the same as the CRS of our basin, `basin`. We could verify this by asking:\n",
    "\n",
    "```python\n",
    "ds.rio.crs == basin.crs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6d0241-8a7d-46b2-ae0e-7effa3dcae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clip = ds.rio.clip(basin.geometry.values)\n",
    "ds_clip.precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07131ad-b20a-497a-bff0-3a35410532b3",
   "metadata": {},
   "source": [
    "We can already tell that the new dataset, `ds_clip`, is smaller. Let's plot it, to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04934b5-7fe5-4b7f-b7db-85e9bffe0cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_clip.precipitation[0].plot(x = 'lon')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b313b2-ae29-484f-bdab-4e96606e474c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Creating a data processing pipeline\n",
    "\n",
    "This worked great for a single Dataset, but we have several files to process. Let's create a `for` loop to deal with them.\n",
    "\n",
    "The `concat()` function in `xarray` can be used to combine multiple datasets together into a single dataset. Here, because each of our IMERG-Final data granules represents a different date (month), we combine them together along the `time` axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace14ed4-a1db-43f1-9af7-4b92fbe54521",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "\n",
    "for filename in file_list:\n",
    "    date = datetime.datetime.strptime(filename.split('.')[4][0:8], '%Y%m%d')\n",
    "    ds0 = xr.open_dataset(filename, group = 'Grid', decode_times = False).get(['precipitation'])\n",
    "    ds0 = ds0.assign_coords({\n",
    "        'time': [date], 'x': longitude, 'y': latitude\n",
    "    })\n",
    "\n",
    "    # Tell xarray that this dataset's CRS is the WGS84 Geographic Coordinate System\n",
    "    ds0 = ds0.rio.write_crs(CRS.from_epsg(4326))\n",
    "    \n",
    "    # Also, we need to indicate which of the coordinates correspond to X and Y dimensions\n",
    "    ds0 = ds0.rio.set_spatial_dims(x_dim = 'lon', y_dim = 'lat')\n",
    "\n",
    "    ds_clip = ds0.rio.clip(basin.geometry.values)\n",
    "    \n",
    "    # Only write the file if it doesn't exist (in case we run this again)\n",
    "    datasets.append(ds_clip)\n",
    "\n",
    "# Combine the datasets together along the \"time\" axis\n",
    "ds = xr.concat(datasets, dim = 'time')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03eff044-38a1-4a04-a00b-24d71bfb7b75",
   "metadata": {},
   "source": [
    "## Calculating total basin-wide precipitation rate\n",
    "\n",
    "Next, we need to convert the units of measurement. We currently have precipitation measured in mm/hr but we have monthly data. To convert from mm/hr to mm/month, we need to figure out how many days are in each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d864b8-ba5a-4f62-a647-e29d1a4e728c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "calendar.mdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d4cc6-411e-40d5-9280-fbcd9ba3b39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "days_in_month = np.array(calendar.mdays)[ds.coords['time.month'].values]\n",
    "days_in_month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca24be-a08d-4298-aa25-ffe7d5fa16da",
   "metadata": {},
   "source": [
    "It seems easy enough to multiply our monthly data, with its hourly rate, by the number of days (and 24 hours). However, when we're working with array data, we have to pay attention to the shape of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d8e00-e565-498d-8391-8bc1284a6fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.precipitation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c33938-5b0c-45ff-8838-2707eab967c1",
   "metadata": {},
   "source": [
    "Our precipitation data are stored as a NumPy array with three axes:\n",
    "\n",
    "- 120 months\n",
    "- 72 rows (each 0.1 degrees latitude)\n",
    "- 53 columns (each 0.1 degrees longitude)\n",
    "\n",
    "When we multiply arrays, they should have the same shape, so we also need to reshape our `days_in_month` array to match the shape of our precipitation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d0c22-57ef-4440-9e75-b00210cc5a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting from [mm hour-1] to [mm month-1]\n",
    "ds['precip_monthly'] = ds.precipitation * 24 * days_in_month.reshape((days_in_month.size, 1, 1))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36dbdf9-d41b-4d7c-aa01-c42f7509887a",
   "metadata": {},
   "source": [
    "**Finally, we're ready to compute the total precipitation for our basin.**\n",
    "\n",
    "#### &#x1F6A9; <span style=\"color:red\">Computing Total Precipitation</red>\n",
    "\n",
    "You may be tempted to compute the sum of all the pixels in the basin in order to determine the total precipitation that fell in a given month. However, this would be grossly exaggerating the amount of precipitation, because our units of measurement (mm/hr or mm/month) are tied to a specific spatial area. That is, the vertical height of standing water (measured in mm) corresponds to a fixed area. If the area were larger, the vertical height of water would be lower as the water spreads out to cover the larger area. **We actually want to compute the mean of our basin's precipitation amounts.**\n",
    "\n",
    "Another way to think about this is to imagine we have a tank with a removable divider, separating the tank into two regions of equal area. On the left of the divider, the water is 4 mm deep. On the right, the water is 2 mm deep. If we removed the divider, how deep would the water be after it settles? It would be 3 mm deep, which corresponds to the average of 2 and 4, not the sum.\n",
    "\n",
    "&#x1F449; For an `xarray` Dataset, when we are computing the average over the entire basin, we specify that we want to collapse both the `'lon'` and the `'lat'` axes, leaving us with only the `'time'` axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada57f3-8499-48b2-8027-a13f11ca2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean over all longitude-latitude bins\n",
    "precip_series = ds.precip_monthly.mean(['lon','lat']).values\n",
    "\n",
    "# Plot the result\n",
    "pyplot.plot(precip_series)\n",
    "pyplot.ylabel('Basin-wide precipitation (mm per month)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973ab58-e561-4c0a-b1b7-d426f1059907",
   "metadata": {},
   "source": [
    "Now, we're ready to save our dataset for later use. Let's save it to a netCDF4 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c178b329-ecdc-441f-b179-e8299135956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_netcdf('./processed/IMERG-Final_precip_monthly_2014-2023.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScienceCore",
   "language": "python",
   "name": "sciencecore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
