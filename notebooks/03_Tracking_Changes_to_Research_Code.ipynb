{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f72887a5-e703-4b09-aebd-80e1af46fe41",
   "metadata": {},
   "source": [
    "# M3.3 - Tracking Changes to Research Code\n",
    "\n",
    "*Part of:* [**Open Science for Water Resources**](https://github.com/OpenClimateScience/M3-Open-Science-for-Water-Resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f28068-7b2d-4b66-96a6-b2b3ea3a8271",
   "metadata": {},
   "source": [
    "In the previous section, we processed IMERG-Final global precipitation data into a monthly precipitation time series for our basin. **It's likely we would want to save and repeat this analysis in the future.** There are several reasons for this:\n",
    "\n",
    "- We might want to run this analysis for a different basin.\n",
    "- We might want to run this analysis for hundreds or thousands of other basins and compare the results.\n",
    "- Someone else might ask us to run this analysis for a basin they are interested in; or ask if they can use our code.\n",
    "- We might discover a mistake in our analysis that requires us to process the data again (after correcting the mistake).\n",
    "\n",
    "**For any of these reasons, we should always ask the following question about research code we generate: *Is it likely that someone, including me, will want to run this code again?***\n",
    "\n",
    "If the answer is \"Yes,\" then we need to think about what comes next. If we change the code in the future, we might unintentionally break something that is currently working. We might decide that new features we added aren't really necessary and the code would be better without them. Someone else might decide to adapt our code for a completely different purpose. And we might want to work with different versions of the same code; for example, a stable version that is commonly used and an experimental version that has more features.\n",
    "\n",
    "**Source control management (SCM), sometimes called \"version control,\" can help with these issues.** To see how SCM works, let's revisit our precipitation analysis code.\n",
    "\n",
    "Below, all we've done so far is to combine the code into a single code cell and to move the `import` statements to the top of the code block, where they belong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504d3d5c-0be5-4398-a69e-f7de7e34d89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "import datetime\n",
    "import glob\n",
    "import earthaccess\n",
    "import numpy as np\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import geopandas\n",
    "from matplotlib import pyplot\n",
    "from pyproj import CRS\n",
    "\n",
    "auth = earthaccess.login()\n",
    "\n",
    "basin = geopandas.read_file('/home/arthur.endsley/Workspace/NTSG/projects/Y2024_TOPS_Training/data/YellowstoneRiver_drainage_WSG84.shp')\n",
    "\n",
    "# results = earthaccess.search_data(\n",
    "#     short_name = 'GPM_3IMERGM',\n",
    "#     temporal = ('2014-01-01', '2023-12-31'))\n",
    "# earthaccess.download(results, 'data/IMERG-Final_monthly')\n",
    "\n",
    "file_list = glob.glob('data/IMERG-Final_monthly/*.HDF5')\n",
    "file_list.sort()\n",
    "\n",
    "datasets = []\n",
    "for i, filename in enumerate(file_list):\n",
    "    # Only need to do this once, for the first file\n",
    "    if i == 0:\n",
    "        with h5py.File(filename, 'r') as hdf:\n",
    "            longitude = hdf['Grid/lon'][:]\n",
    "            latitude = hdf['Grid/lat'][:]\n",
    "\n",
    "    # Get the date of this image\n",
    "    date = datetime.datetime.strptime(filename.split('.')[4][0:8], '%Y%m%d')\n",
    "    ds0 = xr.open_dataset(\n",
    "        filename, group = 'Grid', decode_times = False).get(['precipitation'])\n",
    "    # Define the missing coordinates\n",
    "    ds0 = ds0.assign_coords({\n",
    "        'time': [date], 'x': longitude, 'y': latitude\n",
    "    })\n",
    "    \n",
    "    # Define the coordinate reference system (CRS) and the spatial coordinates\n",
    "    ds0 = ds0.rio.write_crs(CRS.from_epsg(4326))\n",
    "    ds0 = ds0.rio.set_spatial_dims('lon', 'lat')\n",
    "\n",
    "    # Clip the IMERG-Final precipitation data to our basin's boundary\n",
    "    ds_clip = ds0.rio.clip(basin.geometry.values)\n",
    "    \n",
    "    # Save the clipped dataset to be merged with the others\n",
    "    datasets.append(ds_clip)\n",
    "\n",
    "# Merge the datasets together along the \"time\" axis (i.e., build a time series)\n",
    "ds = xr.concat(datasets, dim = 'time')\n",
    "\n",
    "# Converting from [mm hour-1] to [mm month-1]\n",
    "days_in_month = np.array(calendar.mdays)[ds.coords['time.month'].values]\n",
    "ds['precip_monthly'] = ds.precipitation * 24 * days_in_month.reshape((days_in_month.size, 1, 1))\n",
    "\n",
    "# Compute basin-wide monthly precipitation\n",
    "precip_series = ds.precip_monthly.mean(['lon','lat']).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c91e172-a0d5-431e-8423-0816417579fb",
   "metadata": {},
   "source": [
    "## Adapting research code for re-use\n",
    "\n",
    "We started this discussion with the idea that our code will be re-used. When we want to re-use code, we typically write a **function.** **What parts of our analysis could be easily re-written as more general-purpose functions?**\n",
    "\n",
    "Let's start by decomposing our analysis into a series of simple steps:\n",
    "\n",
    "1. Download the IMERG-Final data for a given period.\n",
    "2. Open one of the IMERG-Final data granules to read the latitude and longitude coordinates.\n",
    "3. For each data granule, create an `xarray` Dataset with the proper coordinates.\n",
    "4. For each data granule, clip the Dataset to the bounds of our basin.\n",
    "5. Merge the Datasets together.\n",
    "6. Convert the units of precipitation.\n",
    "7. Calculate the basin-wide average monthly precipitation.\n",
    "\n",
    "Step 3 seems like a good candidate for turning into a general-purpose function. Why? The IMERG-Final data are stored as HDF5 files and we have to do a lot of work to prepare them for use with `xarray`. **The *boilerplate code* we wrote to achieve this isn't specific to our analysis; we'd have to do it every time for every IMERG-Final data granule.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdcd58-bafd-4e24-ad80-5932eaf806e6",
   "metadata": {},
   "source": [
    "#### &#x1F3C1; Challenge: Re-writing Code as a Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358940a4-4acf-4fa3-97ae-44a0c3d63096",
   "metadata": {},
   "source": [
    "Functions generally transform inputs (arguments) into outputs (the return value). When looking at existing code to determine if it can be re-written as a function, we might look for parts of our code where *a single argument* is used multiple times.\n",
    "\n",
    "For example, in this section of our code, we use the `filename` variable a lot!\n",
    "\n",
    "<code>\n",
    "    with h5py.File(<span style = \"background-color:yellow\">filename</span>, 'r') as hdf:\n",
    "        longitude = hdf['Grid/lon'][:]\n",
    "        latitude = hdf['Grid/lat'][:]\n",
    "    # Get the date of this image\n",
    "    date = datetime.datetime.strptime(<span style = \"background-color:yellow\">filename</span>.split('.')[4][0:8], '%Y%m%d')\n",
    "    ds0 = xr.open_dataset(\n",
    "        <span style = \"background-color:yellow\">filename</span>, group = 'Grid', decode_times = False).get(['precipitation'])\n",
    "</code>\n",
    "<br />\n",
    "\n",
    "**This suggests that the entire section (above) could be re-written as a function that takes `filename` as an argument. Try writing the function for Step 3 yourself, then compare it with our answer, below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2234a17a-7d20-40b2-9cdf-10587819cfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdf5_to_xarray_dataset(filename, longitude = None, latitude = None):\n",
    "    '''\n",
    "    Reads an HDF5 file representing daily data and returns an \n",
    "    xarray.Dataset with the date, latitude, and longitude coordinates\n",
    "    properly defined.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        The file path to the HDF5 file\n",
    "    longitude : numpy.ndarray\n",
    "        The longitude coordinates, as a 1D NumPy array\n",
    "    latitude : numpy.ndarray\n",
    "        The latitude coordinates, as a 1D NumPy array\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xarray.Dataset\n",
    "    '''\n",
    "    if longitude is None or latitude is None:\n",
    "        with h5py.File(filename, 'r') as hdf:\n",
    "            longitude = hdf['Grid/lon'][:]\n",
    "            latitude = hdf['Grid/lat'][:]\n",
    "\n",
    "    # Get the date of this image\n",
    "    date = datetime.datetime.strptime(filename.split('.')[4][0:8], '%Y%m%d')\n",
    "    ds0 = xr.open_dataset(\n",
    "        filename, group = 'Grid', decode_times = False).get(['precipitation'])\n",
    "    # Define the missing coordinates\n",
    "    ds0 = ds0.assign_coords({\n",
    "        'time': [date], 'x': longitude, 'y': latitude\n",
    "    })\n",
    "    \n",
    "    # Define the coordinate reference system (CRS) and the spatial coordinates\n",
    "    ds0 = ds0.rio.write_crs(CRS.from_epsg(4326))\n",
    "    ds0 = ds0.rio.set_spatial_dims('lon', 'lat')\n",
    "    return ds0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728a386e-8ba5-4ed9-ae6e-03dc68001d49",
   "metadata": {},
   "source": [
    "#### &#x1F3AF; Best Practice\n",
    "\n",
    "There is one important thing to note about our `hdf_to_xarray_dataset()` function.\n",
    "\n",
    "We already know this function is going to be used inside a `for` loop, so we should think carefully about what happens inside the function. If there's a potentially time-consuming operation that only needs to be done once, we should exclude it from the function. \n",
    "\n",
    "We solved this problem by making `longitude` and `latitude` into optional arguments; if the function is going to be used inside a `for` loop, the user can provide these arguments to avoid having to read the HDF5 file with `h5py` multiple times. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd854553-7b1f-4a24-9c99-0f3e82855642",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Version control for research code\n",
    "\n",
    "With our `hdf5_to_xarray_dataset()` function already defined, we can put the rest of our code into a `main()` function, as below. This enables us to represent the entire workflow as a single Python script.\n",
    "\n",
    "```python\n",
    "import calendar\n",
    "import datetime\n",
    "import glob\n",
    "import earthaccess\n",
    "import numpy as np\n",
    "import h5py\n",
    "import xarray as xr\n",
    "import geopandas\n",
    "from matplotlib import pyplot\n",
    "from pyproj import CRS\n",
    "\n",
    "BASIN_FILE = '/home/arthur.endsley/Workspace/NTSG/projects/Y2024_TOPS_Training/data/YellowstoneRiver_drainage_WSG84.shp'\n",
    "\n",
    "def main():\n",
    "    auth = earthaccess.login()\n",
    "    basin = geopandas.read_file(BASIN_FILE)\n",
    "    \n",
    "    results = earthaccess.search_data(\n",
    "        short_name = 'GPM_3IMERGM',\n",
    "        temporal = ('2014-01-01', '2023-12-31'))\n",
    "    earthaccess.download(results, 'data/IMERG-Final_monthly')\n",
    "    file_list = glob.glob('data/IMERG-Final_monthly/*.HDF5')\n",
    "    file_list.sort()\n",
    "    \n",
    "    datasets = []\n",
    "    for i, filename in enumerate(file_list):\n",
    "        # Only need to do this once, for the first file\n",
    "        if i == 0:\n",
    "            with h5py.File(filename, 'r') as hdf:\n",
    "                longitude = hdf['Grid/lon'][:]\n",
    "                latitude = hdf['Grid/lat'][:]\n",
    "\n",
    "        # Read the HDF5 file as an xarray Dataset, clip it to\n",
    "        #    out basin's boundary\n",
    "        ds0 = hdf5_to_xarray_dataset(filename, longitude, latitude)\n",
    "        ds_clip = ds0.rio.clip(basin.geometry.values)\n",
    "        datasets.append(ds_clip)\n",
    "    \n",
    "    # Merge the datasets together along the \"time\" axis (i.e., build a time series)\n",
    "    ds = xr.concat(datasets, dim = 'time')\n",
    "    \n",
    "    # Converting from [mm hour-1] to [mm month-1], then compute basin-wide\n",
    "    #    monthly precip.\n",
    "    days_in_month = np.array(calendar.mdays)[ds.coords['time.month'].values]\n",
    "    ds['precip_monthly'] = ds.precipitation * 24 * days_in_month.reshape((days_in_month.size, 1, 1))\n",
    "    precip_series = ds.precip_monthly.mean(['lon','lat']).values\n",
    "```\n",
    "\n",
    "<br />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976b6436-8ae5-4262-a2b1-0afb9c24036b",
   "metadata": {},
   "source": [
    "Remember these important lines?\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "```\n",
    "\n",
    "[Review this previous lesson if you need to recall what they are for.](https://github.com/OpenClimateScience/M2-Computational-Climate-Science/blob/main/notebooks/05_Creating_a_Reproducible_Climate_Data_Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db0ca8d-9889-4cf2-a3aa-e4a978df9fe2",
   "metadata": {},
   "source": [
    "### Initializing a `git` repository\n",
    "\n",
    "### Tracking changes to research code\n",
    "\n",
    "### Finalizing changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d0a301-7144-446f-a5e2-bff1049aa035",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Updating research software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5994a361-4762-4e02-9994-ed3116315427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_et(toa_radiation, temp_max, temp_min, temp_mean):\n",
    "    '''\n",
    "    Calculates potential evapotranspiration, according to the Hargreaves\n",
    "    equation:\n",
    "\n",
    "    PET = 0.0023 * R * sqrt(Tmax - Tmin) * (Tmean + 17.8)\n",
    "\n",
    "    Where R is the top-of-atmosphere (TOA) radiation (mm month-1); Tmax and \n",
    "    Tmin are the maximum and minimum monthly air temperatures (degrees C),\n",
    "    respectively; and Tmean is monthly mean air temperature (degrees C).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    toa_radiation : Number\n",
    "        The top-of-atmosphere (TOA) radiation (mm day-1)\n",
    "    temp_max : Number\n",
    "        Maximum monthly air temperature (degrees C)\n",
    "    temp_min : Number\n",
    "        Minimum monthly air temperature (degrees C)\n",
    "    temp_mean : Number\n",
    "        Average monthly air temperature (degrees C)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Number\n",
    "        The potential evapotranspiration (PET) in [mm day-1]\n",
    "    '''\n",
    "    return 0.0023 * toa_radiation * np.sqrt(temp_max - temp_min) * (temp_mean + 17.8)\n",
    "\n",
    "\n",
    "def toa_radiation(latitude, doy):\n",
    "    '''\n",
    "    Top-of-atmosphere (TOA) radiation for a given latitude (L) and day of year\n",
    "    (DOY) can be calculated as:\n",
    "\n",
    "    R = ((24 * 60) / pi) * G * d * (w * sin(L) * sin(D) + cos(L) * cos(D) * sin(w))\n",
    "\n",
    "    Where G is the solar constant, 0.0820 [MJ m-2 day-1]; d is the (inverse) \n",
    "    relative earth-sun distance; w is the sunset hour angle; and D is the solar\n",
    "    declination angle.\n",
    "    \n",
    "    For more information, consult the FAO documentation:\n",
    "\n",
    "        https://www.fao.org/4/X0490E/x0490e07.htm#radiation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    latitude : float\n",
    "        The latitude on earth, in degrees, where southern latitudes\n",
    "        are represented as negative numbers\n",
    "    doy : int\n",
    "        The day of the year (DOY), an integer on [1,366]\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Number\n",
    "        Top-of-atmosphere (TOA) radiation, in [MJ m-2 day-1]\n",
    "    '''\n",
    "    assert isinstance(doy, int) or issubclass(doy.dtype.type, np.integer), 'The \"doy\" argument must be an integer'\n",
    "    assert np.all(doy >= 1) and np.all(doy <= 366), 'The \"doy\" argument must be between 1 and 366, inclusive'\n",
    "    \n",
    "    solar_constant = 0.0820 # [MJ m-2 day-1]\n",
    "    pi = 3.14159\n",
    "    \n",
    "    # Convert latitude from degrees to radians\n",
    "    latitude_radians = np.deg2rad(latitude)\n",
    "    # Inverse Earth-Sun distance (relative), as a function of day-of-year (DOY)\n",
    "    earth_sun_dist = 1 + 0.0033 * np.cos((doy * 2 * pi) / 365)\n",
    "    # Solar declination, as a function of DOY\n",
    "    declination = 0.409 * np.sin(((doy * 2 * pi) / 365) - 1.39)\n",
    "    \n",
    "    # Sunset hour angle; we use np.where() below to guard against\n",
    "    #   warnings where arccos() would return invalid values, which\n",
    "    #   happens when the argument is outside [-1, 1]\n",
    "    _hour_angle = -np.tan(latitude_radians) * np.tan(declination)\n",
    "    _hour_angle = np.where(np.abs(_hour_angle) > 1, np.nan, _hour_angle)\n",
    "    sunset_hour_angle = np.arccos(_hour_angle)\n",
    "\n",
    "    # Incident radiation, depends only on the relative earth-sun distance\n",
    "    inc_radiation = ((24 * 60) / pi) * solar_constant * earth_sun_dist\n",
    "    return inc_radiation * (sunset_hour_angle * np.sin(latitude_radians) * np.sin(declination) +\n",
    "            np.cos(latitude_radians) * np.cos(declination) * np.sin(sunset_hour_angle))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ScienceCore",
   "language": "python",
   "name": "sciencecore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
